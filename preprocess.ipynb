{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m2025-04-02 21:50:20,468 - [INFO] Running build_indicator_json.py...\u001b[0m\n",
      "\u001b[94m2025-04-02 21:50:20,595 - [INFO] - [build_indicator_json] - \u001b[0m\n",
      "\u001b[92m2025-04-02 21:50:20,606 - [SUCCESS] build_indicator_json - Completed successfully.\u001b[0m\n",
      "\u001b[94m2025-04-02 21:50:20,606 - [INFO] Running build_metadata_json.py...\u001b[0m\n",
      "\u001b[94m2025-04-02 21:50:20,690 - [INFO] - [build_metadata_json] - \u001b[0m\n",
      "\u001b[92m2025-04-02 21:50:20,700 - [SUCCESS] build_metadata_json - Completed successfully.\u001b[0m\n",
      "\u001b[94m2025-04-02 21:50:20,700 - [INFO] Running build_standarization_json.py...\u001b[0m\n",
      "\u001b[94m2025-04-02 21:50:20,775 - [INFO] - [build_standarization_json] - \u001b[0m\n",
      "\u001b[92m2025-04-02 21:50:20,785 - [SUCCESS] build_standarization_json - Completed successfully.\u001b[0m\n",
      "\u001b[94m2025-04-02 21:50:20,785 - [INFO] Running download_macro.py...\u001b[0m\n",
      "\u001b[94m2025-04-02 21:50:50,013 - [INFO] - [download_macro] - \u001b[0m\n",
      "\u001b[94m2025-04-02 21:50:51,760 - [INFO] - [download_macro] - \u001b[0m\n",
      "\u001b[94m2025-04-02 21:50:52,600 - [INFO] - [download_macro] - \u001b[0m\n",
      "\u001b[94m2025-04-02 21:51:02,816 - [INFO] - [download_macro] - \u001b[0m\n",
      "\u001b[94m2025-04-02 21:51:03,454 - [INFO] - [download_macro] - \u001b[0m\n",
      "\u001b[94m2025-04-02 21:51:04,070 - [INFO] - [download_macro] - \u001b[0m\n",
      "\u001b[94m2025-04-02 21:51:04,682 - [INFO] - [download_macro] - \u001b[0m\n",
      "\u001b[94m2025-04-02 21:51:05,288 - [INFO] - [download_macro] - \u001b[0m\n",
      "\u001b[94m2025-04-02 21:51:06,117 - [INFO] - [download_macro] - \u001b[0m\n",
      "\u001b[94m2025-04-02 21:51:06,627 - [INFO] - [download_macro] - \u001b[0m\n",
      "\u001b[94m2025-04-02 21:51:13,426 - [INFO] - [download_macro] - \u001b[0m\n",
      "\u001b[94m2025-04-02 21:51:14,921 - [INFO] - [download_macro] - \u001b[0m\n",
      "\u001b[94m2025-04-02 21:51:16,049 - [INFO] - [download_macro] - \u001b[0m\n",
      "\u001b[94m2025-04-02 21:51:17,384 - [INFO] - [download_macro] - \u001b[0m\n",
      "\u001b[0m2025-04-02 21:51:17,514 - [ERROR] - [download_macro] - Starting download from WorldBankAPI\u001b[0m\u001b[0m\n",
      "\u001b[0m2025-04-02 21:51:17,515 - [ERROR] - [download_macro] - Starting download from IMFAPI\u001b[0m\u001b[0m\n",
      "\u001b[0m2025-04-02 21:51:17,515 - [ERROR] - [download_macro] - Starting download from OECDAPI\u001b[0m\u001b[0m\n",
      "\u001b[0m2025-04-02 21:51:17,515 - [ERROR] - [download_macro] - Starting download from AlphaVantageAPI\u001b[0m\u001b[0m\n",
      "\u001b[0m2025-04-02 21:51:17,515 - [ERROR] - [download_macro] - data fetching and saving completed.\u001b[0m\u001b[0m\n",
      "\u001b[92m2025-04-02 21:51:17,515 - [SUCCESS] download_macro - Completed successfully.\u001b[0m\n",
      "Pipeline executed because data/00--raw/macro was empty or did not exist.\n"
     ]
    }
   ],
   "source": [
    "# run this cell to download data!\n",
    "\n",
    "import os\n",
    "\n",
    "directory_path = \"data/00--raw/macro\"\n",
    "\n",
    "if not os.path.exists(directory_path) or not os.listdir(directory_path):\n",
    "    !python3 -m src.fetch.pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import List, Dict\n",
    "from src.preprocess.dataset import Dataset\n",
    "\n",
    "\n",
    "dataset = Dataset()\n",
    "\n",
    "# list of dataset names\n",
    "names : List[str] = dataset.get_dataset_names()\n",
    "\n",
    "# lost of category names\n",
    "categories : List[str] = dataset.get_category_names()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary with key=names : value=dataframe\n",
    "\n",
    "\"\"\"\n",
    "{\"feature1\" : dataframe}\n",
    "\n",
    "frames in format:\n",
    "year | country1 | country2 ...\n",
    "2019 | value1   | value2   \n",
    "\"\"\"\n",
    "\n",
    "datadict : Dict[str, pd.DataFrame] = dataset.get_datadict()\n",
    "\n",
    "for key in list(datadict.keys()): \n",
    "    print(f\"{key}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single dataframe in format\n",
    "\"\"\"\n",
    "year country   |  feature1 |  feature2 ...\n",
    "2019 country1  |  value    |  value    ...\n",
    "2019 country2  |  value    |  value    ...\n",
    "2019 country3  |  value    |  value    ...\n",
    "...\n",
    "2020 country1  |  feature1 |  value    ...\n",
    "2020 country2  |  feature1 |  value    ...\n",
    "2020 country3  |  feature1 |  value    ...\n",
    "...\n",
    "\"\"\"\n",
    "\n",
    "ml_data : pd.DataFrame = dataset.get_ml_ready()\n",
    "print(ml_data.head().to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
